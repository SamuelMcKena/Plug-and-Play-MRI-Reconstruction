{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c97c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MRI data set up.\n",
    "#1. Import TAR file\n",
    "#2. Extract to a TestData and TrainData folder.\n",
    "\n",
    "\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tar_path = \"D:\\Code\\TestData\\knee_singlecoil_test.tar\"\n",
    "# Destination directory to extract to\n",
    "test_path = \"D:\\Code\\TestData\\knee-singlecoil\\singlecoil_test\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of files in the extracted directory\n",
    "def count_files_in_directory(test_path):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(test_path):\n",
    "        count += len(files)\n",
    "    return count\n",
    "\n",
    "# Count the files\n",
    "file_count = count_files_in_directory(test_path)\n",
    "\n",
    "print(f\"Number of files in the directory: {count_files_in_directory(test_path)}\")\n",
    "\n",
    "# Extract\n",
    "if len(os.listdir(test_path)) == 0: \n",
    "    print(\"Extracting TAR file...\")\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=test_path)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Already extracted — skipping.\")\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the first .h5 file\n",
    "file_path = os.path.join(test_path, os.listdir(test_path)[0])  # Get the first file in the list. File_path is defined by joining the data path\n",
    "# and the first file name. Which returns the full path to the first file in the directory. This is done because\n",
    "#the files variable is a list of lists, so we need to access the first element of the first list to get the file name.\n",
    "\n",
    "with h5py.File(file_path, 'r') as f: #use h5py to read the file where 'r' means read-only and 'f' is the file object\n",
    "    print(\"Keys:\", list(f.keys()))  # Discover dataset structure\n",
    "    kspace = f['kspace'][()]  # Load the k-space data\n",
    "\n",
    "# Visualize one slice\n",
    "slice_index = 30\n",
    "image = np.fft.ifft2(kspace[slice_index])\n",
    "image_abs = np.abs(image)\n",
    "\n",
    "plt.imshow(image_abs, cmap='gray')\n",
    "plt.title(f\"Reconstructed MRI Slice {slice_index}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "tar_path = \"D:\\Code\\ValData\\knee_singlecoil_val.tar\"\n",
    "# Destination directory to extract to\n",
    "val_path = \"D:\\Code\\ValData\\singlecoil_val\"\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of files in the extracted directory\n",
    "def count_files_in_directory(val_path):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(val_path):\n",
    "        count += len(files)\n",
    "    return count\n",
    "\n",
    "# Count the files\n",
    "file_count = count_files_in_directory(val_path)\n",
    "\n",
    "print(f\"Number of files in the directory: {count_files_in_directory(test_path)}\")\n",
    "\n",
    "# Extract\n",
    "if len(os.listdir(val_path)) == 0: \n",
    "    print(\"Extracting TAR file...\")\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=val_path)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Already extracted — skipping.\")\n",
    "val_path = \"D:\\Code\\ValData\\singlecoil_val\\singlecoil_val\"\n",
    "\n",
    "file_path = os.path.join(val_path, os.listdir(val_path)[0])  \n",
    "with h5py.File(file_path, 'r') as f: #use h5py to read the file where 'r' means read-only and 'f' is the file object\n",
    "    print(\"Keys:\", list(f.keys()))  # Discover dataset structure\n",
    "    kspace = f['kspace'][()]  # Load the k-space data\n",
    "\n",
    "# Visualize one slice\n",
    "slice_index = 1\n",
    "image = np.fft.ifft2(kspace[slice_index])\n",
    "image_abs = np.abs(image)\n",
    "\n",
    "plt.imshow(image_abs, cmap='gray')\n",
    "plt.title(f\"Reconstructed MRI Slice {slice_index}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "def create_variable_density_mask(kspace_shape, accel_factor, center_fraction):\n",
    "    ny, nx = kspace_shape[-2], kspace_shape[-1]\n",
    "    mask = np.zeros((ny, nx), dtype=np.float32)\n",
    "\n",
    "    # Preserve central region (square box)\n",
    "    center_ny = int(ny * center_fraction)\n",
    "    center_nx = int(nx * center_fraction)\n",
    "    y_start = ny // 2 - center_ny // 2\n",
    "    x_start = nx // 2 - center_nx // 2\n",
    "    mask[y_start:y_start + center_ny, x_start:x_start + center_nx] = 1\n",
    "\n",
    "    # Add variable density sampling elsewhere (e.g. lines or radial-like pattern)\n",
    "    num_total_samples = int(ny * nx / accel_factor)\n",
    "    current_samples = int(mask.sum())\n",
    "\n",
    "    while current_samples < num_total_samples:\n",
    "        y = np.random.randint(0, ny)\n",
    "        x = np.random.randint(0, nx)\n",
    "        if mask[y, x] == 0:\n",
    "            mask[y, x] = 1\n",
    "            current_samples += 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "#Define undersampling function as a function that takes the frequency domain k-space data and a mask as inputs,\n",
    "#and returns the undersampled k-space data by multiplying the k-space data with the mask.\n",
    "\n",
    "def simulate_undersampling(kspace, mask):\n",
    "    undersampled_kspace =kspace * mask\n",
    "    return undersampled_kspace\n",
    "\n",
    "\n",
    "accel_factor = 3  # Acceleration factor\n",
    "center_fraction = 0.4  # Fraction of central rows to preserve\n",
    "\n",
    "#Visualize the undersampled k-space data vs the original k-space data.\n",
    "file_path = os.path.join(val_path, os.listdir(val_path)[0])  \n",
    "with h5py.File(file_path, 'r') as f: #use h5py to read the file where 'r' means read-only and 'f' is the file object\n",
    "    print(\"Keys:\", list(f.keys()))  # Discover dataset structure\n",
    "    kspace = f['kspace'][()]  # Load the k-space data\n",
    "    print(\"Shape of k-space data:\", kspace.shape)  # Print the shape of the k-space data\n",
    "    \n",
    "slice_index = 34\n",
    "kspace_slice = kspace[slice_index]\n",
    "\n",
    "mask = create_variable_density_mask(kspace.shape, accel_factor, center_fraction)\n",
    "undersampled = simulate_undersampling(kspace_slice, mask)\n",
    "\n",
    "image_full = np.fft.ifft2(kspace_slice)\n",
    "image_undersampled = np.fft.ifft2(undersampled)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.abs(image_full), cmap='gray')\n",
    "plt.title(\"Full k-space Reconstruction\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.abs(image_undersampled), cmap='gray')\n",
    "plt.title(\"Undersampled k-space Reconstruction\")\n",
    "plt.axis('off')\n",
    "    \n",
    "\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "val_data_dir = val_path  # already defined\n",
    "# Define output directories for split data\n",
    "output_base = \"D:\\\\Code\\\\ValData\\\\split_data\"\n",
    "train_dir = os.path.join(output_base, \"train\")\n",
    "val_dir = os.path.join(output_base, \"val\") \n",
    "\n",
    "# Clean folders\n",
    "if os.path.exists(output_base):\n",
    "    shutil.rmtree(output_base)\n",
    "\n",
    "for base in [train_dir, val_dir]:\n",
    "    for sub in [\"original\", \"undersampled\"]:\n",
    "        os.makedirs(os.path.join(base, sub), exist_ok=True)\n",
    "\n",
    "# List and shuffle\n",
    "all_files = [f for f in os.listdir(val_data_dir) if f.endswith('.h5')]\n",
    "random.shuffle(all_files)\n",
    "split_idx = int(0.8 * len(all_files))\n",
    "train_files = all_files[:split_idx]\n",
    "val_files = all_files[split_idx:]\n",
    "\n",
    "# Helper: Apply undersampling to a file and save it\n",
    "def process_file(src_path, dst_original, dst_undersampled):\n",
    "    with h5py.File(src_path, 'r') as f:\n",
    "        kspace = f['kspace'][()]\n",
    "    # Save original\n",
    "    shutil.copy2(src_path, dst_original)\n",
    "    # Create one mask for the whole scan\n",
    "    mask = create_variable_density_mask(kspace.shape, accel_factor=accel_factor, center_fraction=center_fraction)\n",
    "    # Ensure mask is not all zeros\n",
    "    if np.sum(mask) == 0:\n",
    "        raise ValueError(\"Mask is all zeros! Check mask generation.\")\n",
    "    undersampled_kspace = simulate_undersampling(kspace, mask)\n",
    "    # Save new .h5 file\n",
    "    with h5py.File(dst_undersampled, 'w') as f:\n",
    "        f.create_dataset(\"kspace\", data=undersampled_kspace)\n",
    "\n",
    "# Copy and undersample\n",
    "def handle_files(file_list, dest_dir):\n",
    "    for fname in file_list:\n",
    "        src = os.path.join(val_data_dir, fname)\n",
    "        dst_orig = os.path.join(dest_dir, \"original\", fname)\n",
    "        dst_us = os.path.join(dest_dir, \"undersampled\", fname)\n",
    "        process_file(src, dst_orig, dst_us)\n",
    "\n",
    "handle_files(train_files, train_dir)\n",
    "handle_files(val_files, val_dir)\n",
    "\n",
    "print(f\"✅ Split complete with accel_factor={accel_factor}, center_fraction={center_fraction}.\")\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader for training and validation datasets\n",
    "class MRIDataset:\n",
    "    def __init__(self, original_dir, undersampled_dir): \n",
    "        self.original_dir = original_dir\n",
    "        self.undersampled_dir = undersampled_dir\n",
    "        self.original_files = sorted([f for f in os.listdir(original_dir) if f.endswith('.h5')])\n",
    "        self.undersampled_files = sorted([f for f in os.listdir(undersampled_dir) if f.endswith('.h5')])\n",
    "        assert self.original_files == self.undersampled_files, \"File mismatch between original and undersampled folders.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_path = os.path.join(self.original_dir, self.original_files[idx])\n",
    "        undersampled_path = os.path.join(self.undersampled_dir, self.undersampled_files[idx])\n",
    "        with h5py.File(original_path, 'r') as f:\n",
    "            kspace = f['kspace'][()]\n",
    "            slice_idx = kspace.shape[0] // 2\n",
    "            original_slice = kspace[slice_idx]\n",
    "        with h5py.File(undersampled_path, 'r') as f:\n",
    "            kspace_us = f['kspace'][()]\n",
    "            undersampled_slice = kspace_us[slice_idx]\n",
    "        return undersampled_slice.astype(np.complex64), original_slice.astype(np.complex64)\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"f537177fd3c24dd549ed7a74b3389fe1e03b8c42\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "from numpy.fft import ifft2, ifftshift\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Hyperparameters and Paths ---\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "PROJECT_NAME = \"MRI_CNN\"\n",
    "ENTITY = \"convunet\"\n",
    "\n",
    "TRAIN_ORIG = train_dir + \"/original\"\n",
    "TRAIN_US = train_dir + \"/undersampled\"\n",
    "VAL_ORIG = val_dir + \"/original\"\n",
    "VAL_US = val_dir + \"/undersampled\"\n",
    "\n",
    "# --- Weights & Biases Logging ---\n",
    "wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"architecture\": \"3-block CNN\",\n",
    "        \"input_type\": \"undersampled k-space to image space\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- Utility: Convert k-space to image ---\n",
    "def convert_kspace_to_image(kspace):\n",
    "    image = np.abs(ifft2(ifftshift(kspace)))\n",
    "    maxval = np.max(image)\n",
    "    if maxval < 1e-8:\n",
    "        return image\n",
    "    return image / maxval\n",
    "\n",
    "# --- Prepare dataset: Converts k-space pairs to normalized images for training ---\n",
    "def prepare_dataset(dataset, target_size=(160, 160)):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(dataset)):\n",
    "        k_us, k_full = dataset[i]\n",
    "        img_us = np.abs(ifft2(ifftshift(k_us)))\n",
    "        img_gt = np.abs(ifft2(ifftshift(k_full)))\n",
    "        img_us_resized = cv2.resize(img_us, target_size, interpolation=cv2.INTER_AREA)\n",
    "        img_gt_resized = cv2.resize(img_gt, target_size, interpolation=cv2.INTER_AREA)\n",
    "        # Normalize to [0, 1]\n",
    "        min_us, max_us = np.min(img_us_resized), np.max(img_us_resized)\n",
    "        min_gt, max_gt = np.min(img_gt_resized), np.max(img_gt_resized)\n",
    "        img_us_resized = (img_us_resized - min_us) / (max_us - min_us + 1e-8)\n",
    "        img_gt_resized = (img_gt_resized - min_gt) / (max_gt - min_gt + 1e-8)\n",
    "        x.append(img_us_resized[..., np.newaxis])\n",
    "        y.append(img_gt_resized[..., np.newaxis])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# --- Loss: Combined MSE and SSIM for perceptual quality ---\n",
    "def combined_loss(y_true, y_pred):\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    return 0.3 * mse_loss + 0.7 * ssim_loss\n",
    "\n",
    "# --- U-Net Denoiser Model ---\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.BatchNormalization()(c1)\n",
    "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)\n",
    "    c1 = layers.BatchNormalization()(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.BatchNormalization()(c2)\n",
    "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)\n",
    "    c2 = layers.BatchNormalization()(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.BatchNormalization()(c3)\n",
    "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)\n",
    "    c3 = layers.BatchNormalization()(c3)\n",
    "    p3 = layers.MaxPooling2D()(c3)\n",
    "    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(p3)\n",
    "    c4 = layers.BatchNormalization()(c4)\n",
    "    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "    c4 = layers.BatchNormalization()(c4)\n",
    "    # Decoder\n",
    "    u3 = layers.UpSampling2D()(c4)\n",
    "    u3 = layers.concatenate([u3, c3])\n",
    "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(u3)\n",
    "    c5 = layers.BatchNormalization()(c5)\n",
    "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "    c5 = layers.BatchNormalization()(c5)\n",
    "    u2 = layers.UpSampling2D()(c5)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(u2)\n",
    "    c6 = layers.BatchNormalization()(c6)\n",
    "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "    c6 = layers.BatchNormalization()(c6)\n",
    "    u1 = layers.UpSampling2D()(c6)\n",
    "    u1 = layers.concatenate([u1, c1])\n",
    "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(u1)\n",
    "    c7 = layers.BatchNormalization()(c7)\n",
    "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(c7)\n",
    "    c7 = layers.BatchNormalization()(c7)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Data Preparation ---\n",
    "train_dataset = MRIDataset(TRAIN_ORIG, TRAIN_US)\n",
    "val_dataset = MRIDataset(VAL_ORIG, VAL_US)\n",
    "x_train, y_train = prepare_dataset(train_dataset)\n",
    "x_val, y_val = prepare_dataset(val_dataset)\n",
    "\n",
    "# --- Model Training ---\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "model = build_unet(input_shape=x_train.shape[1:])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=combined_loss,\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "        WandbModelCheckpoint(filepath=\"model.keras\", save_best_only=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def pnp_reconstruction(y_kspace, mask, model, iterations=20):\n",
    "    \"\"\"\n",
    "    Plug-and-Play MRI reconstruction.\n",
    "    Alternates between data consistency in k-space and denoising in image space.\n",
    "    Based on: Venkatakrishnan et al., GlobalSIP 2013; Zhang et al., CVPR 2018.\n",
    "    \"\"\"\n",
    "    # Initial guess: zero-filled IFFT (use fftshift/ifftshift for consistency)\n",
    "    x = np.fft.ifft2(np.fft.ifftshift(y_kspace))\n",
    "    x = np.abs(x)\n",
    "    x = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Denoising step (U-Net expects [batch, H, W, 1])\n",
    "        x_in = x[np.newaxis, ..., np.newaxis].astype(np.float32)\n",
    "        x_dn = model.predict(x_in, verbose=0)[0, ..., 0]\n",
    "        # Normalize output\n",
    "        x_dn = (x_dn - x_dn.min()) / (x_dn.max() - x_dn.min() + 1e-8)\n",
    "        # Data consistency step (use fftshift/ifftshift for consistency)\n",
    "        x_dn_k = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(x_dn)))\n",
    "        x_dc_k = mask * y_kspace + (1 - mask) * x_dn_k\n",
    "        x = np.abs(np.fft.ifft2(np.fft.ifftshift(x_dc_k)))\n",
    "        x = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    "    return x\n",
    "\n",
    "# --- Confirm consistent transforms for GT and zero-filled ---\n",
    "# Pick one random sample\n",
    "idx = np.random.choice(len(x_val))\n",
    "gt_img = y_val[idx].squeeze()\n",
    "input_img = x_val[idx].squeeze()\n",
    "# Consistent: get k-space from GT image, then reconstruct with ifft2/ifftshift\n",
    "gt_kspace = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(gt_img)))\n",
    "mask = create_variable_density_mask(gt_kspace.shape, accel_factor=accel_factor, center_fraction=center_fraction)\n",
    "y_kspace = gt_kspace * mask\n",
    "\n",
    "# Zero-filled reconstruction (consistent transform)\n",
    "x_dc = np.abs(np.fft.ifft2(np.fft.ifftshift(y_kspace)))\n",
    "x_dc = x_dc / (np.max(x_dc) + 1e-8)\n",
    "\n",
    "# GT image (reconstructed from k-space, should match original gt_img up to global phase/scale)\n",
    "gt_img_recon = np.abs(np.fft.ifft2(np.fft.ifftshift(gt_kspace)))\n",
    "gt_img_recon = gt_img_recon / (np.max(gt_img_recon) + 1e-8)\n",
    "\n",
    "# PnP reconstruction (using your model)\n",
    "recon_img = pnp_reconstruction(y_kspace, mask, model, iterations=8)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(x_dc, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Undersampled\", fontsize=12)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(gt_img_recon, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Ground Truth\", fontsize=12)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(recon_img, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"PnP Recon\", fontsize=12)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Compute difference maps\n",
    "diff_recon_us = recon_img - x_dc\n",
    "diff_recon_gt = recon_img - gt_img_recon\n",
    "\n",
    "# Quantitative metrics\n",
    "mse_us = np.mean((recon_img - x_dc) ** 2)\n",
    "mae_us = np.mean(np.abs(recon_img - x_dc))\n",
    "ssim_us = ssim(recon_img, x_dc, data_range=1.0)\n",
    "\n",
    "mse_gt = np.mean((recon_img - gt_img_recon) ** 2)\n",
    "mae_gt = np.mean(np.abs(recon_img - gt_img_recon))\n",
    "ssim_gt = ssim(recon_img, gt_img_recon, data_range=1.0)\n",
    "\n",
    "print(f\"Recon vs Undersampled:   MSE={mse_us:.5f}, MAE={mae_us:.5f}, SSIM={ssim_us:.4f}\")\n",
    "print(f\"Recon vs Ground Truth:   MSE={mse_gt:.5f}, MAE={mae_gt:.5f}, SSIM={ssim_gt:.4f}\")\n",
    "\n",
    "# Amplify differences for visualization\n",
    "amplify = 10\n",
    "diff_recon_us_vis = diff_recon_us * amplify\n",
    "diff_recon_gt_vis = diff_recon_gt * amplify\n",
    "\n",
    "# Set symmetric color limits\n",
    "vmax = np.max(np.abs([diff_recon_us_vis, diff_recon_gt_vis]))\n",
    "vmin = -vmax\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(diff_recon_us_vis, cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Recon - Undersampled (amplified)\")\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(diff_recon_gt_vis, cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Recon - Ground Truth (amplified)\")\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 12s/st ━━━━━━━━━━━━━━━━━━━━ 12s 12s/step\n",
      "Dummy test - Output min/max: 0.008599807 0.40358046\n"
     ]
    }
   ],
   "source": [
    "dummy_input = np.random.rand(1, 320, 320, 1).astype(np.float32)\n",
    "output = model.predict(dummy_input)\n",
    "print(\"Dummy test - Output min/max:\", output.min(), output.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eef488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input min/max: 0.0 0.99627686\n",
      "GT min/max: 0.0 0.99626845\n"
     ]
    }
   ],
   "source": [
    "# 1. Check if your input data is nonzero and normalized\n",
    "print(\"Input min/max:\", x_train.min(), x_train.max())\n",
    "print(\"GT min/max:\", y_train.min(), y_train.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
